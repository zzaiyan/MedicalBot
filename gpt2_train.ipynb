{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/mindnlp/utils/download.py:29: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import argparse\n",
    "import numpy as np\n",
    "import logging\n",
    "import mindspore.dataset as ds\n",
    "import os\n",
    "import re\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from mindspore.nn import CrossEntropyLoss\n",
    "from mindspore import nn, ops\n",
    "from mindspore.train.serialization import save_checkpoint\n",
    "from mindspore.dataset import TextFileDataset, GeneratorDataset\n",
    "\n",
    "from mindnlp.transforms import BertTokenizer\n",
    "from mindnlp.modules import Accumulator\n",
    "from mindnlp.models import GPT2Config, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 8\n",
    "\n",
    "lr = 1e-4\n",
    "warmup_steps = 2000\n",
    "accumulate_step = 2\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "log_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./mid_10000.txt') as f:\n",
    "    text_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9656, ['text'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = TextFileDataset(str(path), shuffle=False)\n",
    "dataset = GeneratorDataset(text_data, column_names=['text'])\n",
    "dataset.get_dataset_size(), dataset.get_col_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一直中药治疗能要吗<Paragraph>小时候因发热发作癫痫，一直到现在。发作时呈失神状态，以前要严重些，现在吃中药症状要轻些。曾经在武汉癫痫病治疗，效果不明显<Paragraph><QA>您好， 有癫痫的患者， 一般是不要怀孕的， 会影响孩子的生长和疾病的复发 ， 如果要孩子， 也是没有问题的。 建议去医院咨询治疗癫痫， 康复 后， 在怀孕 。 ，癫痫病患者在积极治疗之外，患者在生活中还需要注意保持合理饮食的好习惯，补充身体营养，希望上述的答案可以帮助到你，谢谢 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(data[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(15662:140220155474624,MainProcess):2023-08-27-10:28:01.679.149 [mindspore/dataset/engine/datasets.py:2309] Dataset is shuffled before split.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, eval_dataset, test_dataset = dataset.split([0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# article: [CLS] xxxxx [SEP]\n",
    "# summary: [CLS] xxxxx [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_dataset(dataset, tokenizer, batch_size=8, max_seq_len=512, shuffle=False):\n",
    "    def read_map(text):\n",
    "        sp = text.item().split('<QA>')\n",
    "        return np.array(sp[0]), np.array(sp[1])\n",
    "#         data = json.loads(text.tobytes())\n",
    "#         return np.array(data['article']), np.array(data['summarization'])\n",
    "\n",
    "    def merge_and_pad(article, summary):\n",
    "        article_len = len(article)\n",
    "        summary_len = len(summary)\n",
    "\n",
    "        sep_id = np.array([tokenizer.sep_token_id])\n",
    "        pad_id = np.array([tokenizer.pad_token_id])\n",
    "        if article_len + summary_len > max_seq_len:\n",
    "            new_article_len = max_seq_len - summary_len\n",
    "            merged = np.concatenate([article[:new_article_len], sep_id, summary[1:]])\n",
    "        elif article_len + summary_len - 1 < max_seq_len:\n",
    "            pad_len = max_seq_len - article_len - summary_len + 1\n",
    "            pad_text = np.array([tokenizer.pad_token_id] * pad_len)\n",
    "            merged = np.concatenate([article, summary[1:], pad_text])\n",
    "        else:\n",
    "            merged = np.concatenate([article, summary[1:]])\n",
    "            \n",
    "        return merged.astype(np.int32)\n",
    "\n",
    "    dataset = dataset.map(read_map, 'text', ['article', 'summary'], ['article', 'summary'])\n",
    "    dataset = dataset.map(tokenizer, 'article')\n",
    "    dataset = dataset.map(tokenizer, 'summary')\n",
    "    dataset = dataset.map(merge_and_pad, ['article', 'summary'], ['input_ids'], ['input_ids'])\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = process_dataset(train_dataset, tokenizer)\n",
    "eval_dataset = process_dataset(eval_dataset, tokenizer)\n",
    "test_dataset = process_dataset(test_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "966it [00:06, 156.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for data in tqdm(train_dataset):\n",
    "#     print(data[0].shape)\n",
    "    data[0].shape\n",
    "#     assert data[0].shape == (8, 1024)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(shape=[8, 512], dtype=Int32, value=\n",
       " [[ 101, 2593, 7444 ...    0,    0,    0],\n",
       "  [ 101, 7332, 2227 ...    0,    0,    0],\n",
       "  [ 101, 5554, 5375 ...    0,    0,    0],\n",
       "  ...\n",
       "  [ 101, 1920,  912 ...    0,    0,    0],\n",
       "  [ 101, 1059, 6716 ...    0,    0,    0],\n",
       "  [ 101, 1079, 5552 ...    0,    0,    0]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dataset.create_tuple_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindnlp._legacy.amp import auto_mixed_precision\n",
    "\n",
    "config = GPT2Config(vocab_size=len(tokenizer))\n",
    "model = GPT2LMHeadModel(config, ignore_index=tokenizer.pad_token_id)\n",
    "# model = auto_mixed_precision(model, 'O1')\n",
    "\n",
    "optimizer = nn.AdamWeightDecay(model.trainable_params(), lr)\n",
    "accumulator = Accumulator(optimizer, accumulate_step, max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mindspore import ops, ms_function\n",
    "from mindspore.amp import init_status, all_finite, DynamicLossScaler\n",
    "# Define forward function\n",
    "\n",
    "loss_scaler = DynamicLossScaler(scale_value=2**10, scale_factor=2, scale_window=1000)\n",
    "\n",
    "def forward_fn(input_ids, labels):\n",
    "    outputs = model(input_ids, labels=labels)\n",
    "    loss = outputs[0]\n",
    "    return loss_scaler.scale(loss / accumulate_step)\n",
    "\n",
    "# Get gradient function\n",
    "grad_fn = ops.value_and_grad(forward_fn, None, model.trainable_params())\n",
    "\n",
    "# Define function of one-step training\n",
    "@ms_function\n",
    "def train_step(data, label):\n",
    "    status = init_status()\n",
    "    data = ops.depend(data, status)\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    loss = loss_scaler.unscale(loss)\n",
    "\n",
    "    is_finite = all_finite(grads, status)\n",
    "    if is_finite:\n",
    "        grads = loss_scaler.unscale(grads)\n",
    "        loss = ops.depend(loss, accumulator(grads))\n",
    "    loss = ops.depend(loss, loss_scaler.adjust(is_finite))\n",
    "    return loss, is_finite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 966/966 [07:55<00:00,  2.03it/s, finite=True, loss=0.9193063, scale_value=1024.0] \n",
      "Epoch 1: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.67552054, scale_value=2048.0]\n",
      "Epoch 2: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.52593833, scale_value=4096.0]\n",
      "Epoch 3: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.38937113, scale_value=8192.0]\n",
      "Epoch 4: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.27627778, scale_value=16384.0]\n",
      "Epoch 5: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.18632828, scale_value=32768.0]\n",
      "Epoch 6: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.12626567, scale_value=65536.0] \n",
      "Epoch 8: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.0709814, scale_value=262144.0]  \n",
      "Epoch 9: 100%|██████████| 966/966 [07:23<00:00,  2.18it/s, finite=True, loss=0.06103498, scale_value=524288.0] \n",
      "Epoch 10:   6%|▌         | 59/966 [00:27<06:51,  2.21it/s, finite=True, loss=0.053688355, scale_value=524288.0]"
     ]
    }
   ],
   "source": [
    "total = train_dataset.get_dataset_size()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with tqdm(total=total) as progress:\n",
    "        progress.set_description(f'Epoch {epoch}')\n",
    "        loss_total = 0\n",
    "        cur_step_nums = 0\n",
    "        for batch_idx, (input_ids,) in enumerate(train_dataset.create_tuple_iterator()):\n",
    "            cur_step_nums += 1\n",
    "            loss, is_finite = train_step(input_ids, input_ids)\n",
    "            loss_total += loss\n",
    "\n",
    "            progress.set_postfix(loss=loss_total/cur_step_nums, finite=is_finite, scale_value=loss_scaler.scale_value.asnumpy())\n",
    "            progress.update(1)\n",
    "        save_checkpoint(model, f'gpt_epoch_finetune_{epoch}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = mindspore.load_checkpoint('./gpt_epoch_finetune_6.ckpt')\n",
    "mindspore.load_param_into_net(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # cleaned_text = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9,.]', ' ', text)\n",
    "    pattern = r\"[^a-zA-Z0-9\\u4e00-\\u9fa5,.\\?!，。？、]\"\n",
    "    cleaned_text = re.sub(pattern, \" \", text)\n",
    "    return cleaned_text.replace('\"', '').replace('\\t', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robot_query(desc, query):\n",
    "    summury = ''\n",
    "\n",
    "#     desc = '年龄十七岁，男孩，最近两三个月出现晚上梦游，尿床等症状，不知道是什么原因。'\n",
    "#     query = '晚上梦游尿床是有什么病症'\n",
    "\n",
    "    max_summary_len = 300\n",
    "    desc, query = clean_text(desc), clean_text(query)\n",
    "    article = f'{query}<Paragraph>{desc}<Paragraph>'\n",
    "    show = article.replace('<Paragraph>', '<sep>')\n",
    "    # article = '浆乳中药能治好吗<Paragraph>肿块较硬  <Paragraph>'\n",
    "    input_ids = tokenizer.encode(article).ids\n",
    "    print(f'query: \\n{show}\\n\\nanswer:')\n",
    "\n",
    "    for _ in range(max_summary_len):\n",
    "        inputs = mindspore.Tensor(input_ids, mindspore.int32)\n",
    "    #     print(inputs.shape)\n",
    "        output = model(inputs)[0]\n",
    "    #     print(output.shape)\n",
    "        pred = output.argmax(-1)[-1]\n",
    "        input_ids.append(pred.asnumpy())\n",
    "        summury = summury + tokenizer.id_to_token(pred.asnumpy())\n",
    "\n",
    "        if summury[-1] == ']':\n",
    "            if summury[-2]!='。':\n",
    "                print('。', end='')\n",
    "            break\n",
    "\n",
    "        print(summury[-1], end='')\n",
    "    \n",
    "# print(summury)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "胆总管结石该如何治疗？<sep>医生我朋友他得了胆结石，他跟我说这个病的具体名称是胆总管结石。我也分不清结石的种类，我不知晓这个病要怎么样治疗，所以我想问一下胆总管结石该如何治疗呢？<sep>\n",
      "\n",
      "answer:\n",
      "您好，胆总管结石应该是个比较小的疾病，比如说结石比较小的话，是可以通过手术的方法治疗，可以决定手术的方法，如果结石比较小的话，可以采用微创手术的方式，互相配合中药的方式，决定清淡饮食，这样对结石有很好的效果。平时要注意多喝水，多吃点新鲜的水果和蔬菜，不要吃辛辣的食物，防止吃许多油腻的食物，油炸的食品等。。"
     ]
    }
   ],
   "source": [
    "# desc = '年龄十七岁，男孩，最近两三个月出现晚上梦游，尿床等症状，不知道是什么原因。'\n",
    "# query = '晚上梦游尿床是有什么病症'\n",
    "\n",
    "query = '胆总管结石该如何治疗？'\n",
    "desc = '医生我朋友他得了胆结石，他跟我说这个病的具体名称是胆总管结石。我也分不清结石的种类，我不知晓这个病要怎么样治疗，所以我想问一下胆总管结石该如何治疗呢？'\n",
    "\n",
    "robot_query(desc, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
